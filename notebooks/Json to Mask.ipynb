{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "import py_wsi\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sys.path.append(\"../code/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "from utils.rle import *\n",
    "\n",
    "from data.dataset import load_image\n",
    "\n",
    "from utils.metrics import dice_scores_img\n",
    "from utils.plots import plot_heatmap_preds, plot_contours_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "IDENTITY = rasterio.Affine(1, 0, 0, 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.read_csv(DATA_PATH + f\"HuBMAP-20-dataset_information.csv\")\n",
    "df_mask = pd.read_csv(DATA_PATH + \"train.csv\")\n",
    "\n",
    "ANNOT_PATH = DATA_PATH + \"annotation_v3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = False\n",
    "ADD_FC = False\n",
    "ONLY_FC = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df = df_mask.copy().set_index('id')\n",
    "\n",
    "# for id_ in tqdm(df_mask['id']):\n",
    "#     print(f' -> {id_}')\n",
    "#     if id_ + \".json\" in os.listdir(ANNOT_PATH):        \n",
    "#         annot = json.load(open(ANNOT_PATH + id_ + \".json\", 'r'))\n",
    "        \n",
    "#         w, h = df_info[df_info['image_file'] == id_ + '.tiff'][['width_pixels', 'height_pixels']].values[0]\n",
    "        \n",
    "#         rle = df_mask[df_mask['id'] == id_]['encoding']\n",
    "        \n",
    "# #         mask = enc2mask(rle, (w, h)).astype(np.uint8)  # smh not working\n",
    "#         mask = np.zeros((h, w), dtype=np.uint8)\n",
    "        \n",
    "#         if not ONLY_FC:\n",
    "#             mask += enc2mask(rle, (w, h)).astype(np.uint8)\n",
    "        \n",
    "#         added = 0\n",
    "#         for info in annot:\n",
    "#             label = info['properties']['classification']['name']\n",
    "\n",
    "#             if label == \"FC\" and not ONLY_FC:\n",
    "#                 if not ADD_FC or id_ != \"aaa6a05cc\":\n",
    "#                     continue\n",
    "                    \n",
    "#             if ONLY_FC and label != \"FC\":\n",
    "#                 continue\n",
    "\n",
    "#             poly = info['geometry']['coordinates']\n",
    "#             try:\n",
    "#                 mask = cv2.fillPoly(mask, np.int32([poly]), True)\n",
    "#             except ValueError:\n",
    "#                 poly = np.concatenate([np.array(poly[i]).squeeze() for i in range(len(poly))])\n",
    "#                 mask = cv2.fillPoly(mask, np.int32([poly]), True)\n",
    "#             added +=1\n",
    "            \n",
    "#         print(f\"Added {added} glomerulis\")\n",
    "        \n",
    "#         new_df.loc[id_] = rle_encode_less_memory(mask)\n",
    "        \n",
    "#         if PLOT:\n",
    "#             img = load_image(os.path.join(TIFF_PATH_4, id_ + \".tiff\"), full_size=False)\n",
    "            \n",
    "#             mask = cv2.resize(\n",
    "#                 mask,\n",
    "#                 (w // 4, h // 4),\n",
    "#                 interpolation=cv2.INTER_NEAREST,\n",
    "#             )\n",
    "#             assert mask.shape == img.shape[:2], (mask.shape, img.shape)\n",
    "        \n",
    "#             fig = plot_contours_preds(img, mask, w=1, downsize=4)\n",
    "#             w = 1000\n",
    "#             h = int(w *  mask.shape[0] / mask.shape[1])\n",
    "#             fig.update_layout(\n",
    "#                 autosize=False,\n",
    "#                 width=w,\n",
    "#                 height=h,\n",
    "#             )\n",
    "\n",
    "#             fig.show()\n",
    "\n",
    "#             break\n",
    "\n",
    "# if not PLOT:\n",
    "#     name = \"train_fix.csv\" if not ADD_FC else \"train_fc.csv\"\n",
    "#     if ONLY_FC:\n",
    "#         name = \"train_onlyfc.csv\"\n",
    "#     new_df.to_csv(DATA_PATH + name)\n",
    "    \n",
    "#     print(f'\\n -> Saved masks to {DATA_PATH + name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = False\n",
    "SAVE_TIFF = False\n",
    "SAVE = True\n",
    "ADD_FC = False\n",
    "ONLY_FC = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files = [p for p in os.listdir(DATA_PATH + \"extra/\") if p.endswith(\"svs\")]\n",
    "rles = {}\n",
    "\n",
    "for file in tqdm(files):\n",
    "    id_ = file[:-4]\n",
    "    print(f' -> {id_}')\n",
    "    \n",
    "#     if id_ != \"SAS_21908_001\":\n",
    "#         continue\n",
    "    \n",
    "    if os.path.exists(ANNOT_PATH + id_ + \".json\"):\n",
    "        original_img = rasterio.open(DATA_PATH + \"extra/\" + file, transform=IDENTITY, num_threads='all_cpus')\n",
    "        img = original_img.read([1, 2, 3]).transpose(1, 2, 0).astype(np.uint8)\n",
    "\n",
    "        shape = img.shape[:2]\n",
    "        \n",
    "        annot = json.load(open(ANNOT_PATH + id_ + \".json\", 'r'))\n",
    "\n",
    "        mask = np.zeros(shape, dtype=np.uint8)\n",
    "\n",
    "        added = 0\n",
    "        for info in annot:\n",
    "            poly = np.array(info['geometry']['coordinates'])\n",
    "            \n",
    "            try:\n",
    "                label = info['properties']['classification']['name']\n",
    "            except KeyError:\n",
    "                print('??')\n",
    "                label = \"G\"\n",
    "            \n",
    "            if not ADD_FC and label == \"FC\":\n",
    "                continue\n",
    "\n",
    "            if ONLY_FC and label != \"FC\":\n",
    "                continue\n",
    "                \n",
    "            poly = info['geometry']['coordinates']\n",
    "            try:\n",
    "                mask = cv2.fillPoly(mask, np.int32([poly]), True)\n",
    "            except ValueError:\n",
    "                poly = np.concatenate([np.array(poly[i]).squeeze() for i in range(len(poly))])\n",
    "                mask = cv2.fillPoly(mask, np.int32([poly]), True)\n",
    "            added += 1\n",
    "        \n",
    "        print(f\"Added {added} glomerulis\")\n",
    "        \n",
    "        if PLOT:\n",
    "            print('plot')\n",
    "            fig = plot_contours_preds(img, mask, w=2, downsize=8)\n",
    "\n",
    "            w = 1000\n",
    "            h = int(w *  mask.shape[0] / mask.shape[1])\n",
    "            fig.update_layout(\n",
    "                autosize=False,\n",
    "                width=w,\n",
    "                height=h,\n",
    "            )\n",
    "\n",
    "            fig.show()\n",
    "\n",
    "            break\n",
    "            \n",
    "        if SAVE:\n",
    "            if SAVE_TIFF:\n",
    "                img = cv2.resize(\n",
    "                    img,\n",
    "                    (img.shape[1] // 2, img.shape[0] // 2),\n",
    "                    interpolation=cv2.INTER_AREA,\n",
    "                )\n",
    "                    \n",
    "                if not os.path.exists(DATA_PATH + \"extra_tiff/\"):\n",
    "                    os.mkdir(DATA_PATH + \"extra_tiff/\")\n",
    "                tifffile.imsave(DATA_PATH + \"extra_tiff/\" + f\"{id_}.tiff\", img)\n",
    "\n",
    "            mask = cv2.resize(\n",
    "                mask,\n",
    "                (mask.shape[1] // 2, mask.shape[0] // 2),\n",
    "                interpolation=cv2.INTER_NEAREST,\n",
    "            )\n",
    "\n",
    "            rles[id_] = rle_encode_less_memory(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annot_extra = pd.DataFrame.from_dict(rles, orient='index', columns=['encoding'])\n",
    "\n",
    "if SAVE and not PLOT:\n",
    "    name = \"train_extra.csv\" if not ADD_FC else \"train_extra_fc.csv\"\n",
    "    if ONLY_FC:\n",
    "        name = \"train_extra_onlyfc.csv\"\n",
    "    df_annot_extra.to_csv(DATA_PATH + name)\n",
    "    print(f'\\n -> Saved masks to {DATA_PATH + name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
